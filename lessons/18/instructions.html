<fudiv id="p1" class="showable_instructions">

  <h2>Conclusions</h2>

  <p>Congratulations on finishing this series of lessons.  We hope you
    enjoyed them!  Beyond just learning about log-linear models, you've now
    seen many other ideas that are pervasive in machine learning:</p>

  <ul>
    <li><b>Modeling</b>
      <ul>
	<li>Defining a family of models
	<li>Defining useful features
	<li>Interactions among model parameters (feature weights)
      </ul>
    <li><b>Some types of model</b>
      <ul>
	<li>Conditional models
	<li>Sequence models
	<li>Logistic regression for binary classification
      </ul>
    <li><b>Parameter estimation</b>
      <ul>
	<li>Fitting your model's parameters to match data
	<li>Log-likelihood and conditional log-likelihood as objective functions
	<li>Gradient ascent and adaptive stepsize
      </ul>
    <li><b>Effects of choosing the objective function</b>
      <ul>
	<li>Overfitting to a small training sample
	<li>Regularization (reduces the variance of your estimated
          parameters on a small training sample)
	<li>Smoothing = fitting the data imperfectly<br>(because the model
	  has fewer parameters than outcomes, or because using too
	  many parameters would be penalized by the regularizer)
	<li>Backoff smoothing = making use of backoff features and not just
	  fine-grained features<br>
	  (to avoid being penalized by the regularizer)
      </ul>
  </ul>

  <p>

  <h2>Efficiency Issues</h2>

  <p>These lessons focused on the case where there are only a few
    possible <i>y</i> values (or only a few for each <i>x</i>), so we
    could show all of them visually.</p>

  <p>But what if <i>y</i> is a large structured object like a
    sentence, a tree, an image, or a graph?  This setting is called
    <u>structured prediction</u> and obviously arises in domains like
    natural language processing.  Then there may be exponentially many
    possible <i>y</i> values, so you can't reasonably loop over all of
    them.</p>

  <p>The reason you'd need such a loop is to find <i>Z</i>(<i>x</i>),
    which sums over all possible <i>y</i> values.  <i>Z</i>(<i>x</i>)
    is needed to compute p(<i>y</i> | <i>x</i>) exactly, or to sample
    a random <i>y</i> given <i>x</i>.  You also need to sum over all
    possible <i>y</i> values during training, in order to get the
    expected counts during training.  (This is actually related, since
    the expected values turn out to be the partial derivatives of
    log <i>Z</i>(<i>x</i>).)</p>

  <p>Depending on your features, you may still be able to do the above
    computations exactly by using <u>dynamic programming</u>.  If not,
    there are various algorithms for <u>approximate inference</u>.
    One approximation approach is to first solve the problem of
    sampling from p(<i>y</i> | <i>x</i>): this part can often be
    approximated with <u>Markov chain Monte Carlo</u> methods such
    as <u>Gibbs sampling</u>.  Then you can loop over a sample
    of <i>y</i> values rather than over all of them.</p>

  <h2>Further Connections</h2>

  <p>Log-linear models are a great way to get started with machine
  learning.  The following connections may be useful if you've seen
  other supervised methods for making predictions, or are planning to
  read about them.</p>

  <p><b>Other names for conditional log-linear models.</b> Log-linear
    models can be found all over machine learning.  The special case of
    binary classification with a conditional log-linear model
    (<A HREF="#17">lesson 17</A>) is known as <u>logistic
      regression.</u>  A <u>conditional random field (CRF)</u> is just a
    conditional log-linear model where the contexts and outcomes are
    complex: typically a CRF models p(Y1=y1, Y2=y2, Y3=y3 | X1=x1,
    X2=x2) by using features on various subsets of the X and Y
    variables.</p>

  <p>These models are also known as <u>maximum-entropy models</u>.
    This is because the log-linear <i>form</i> of the formula for
    p(<i>y</i> |
    <i>x</i>) <A HREF="http://acl.ldc.upenn.edu/J/J96/J96-1002.pdf">can be
      justified</A> as the optimal solution to another problem that
    involves maximizing entropy.  We may add lessons to the tutorial
    that help you visualize this relationship.</p>
  
  <blockquote><small>The basic idea is this.  If you don't know
      anything about your data, then you might make the "safe" guess
      that all outcomes are equally likely (in each context).
      This <i>uniform</i> distribution has the highest entropy of any
      distribution that you could pick.  But you
      <i>do</i> know something from observing training data: you can
      measure the counts of several features.  Then you can insist on
      guessing a distribution whose expected counts = those observed
      counts.  Of all distributions that satisfy those constraints,
      the distribution that has <i>maximum entropy</i> turns out to be
      our best log-linear model.  That is, it is the log-linear
      distribution defined with the same features you measured, and
      with the feature weights set so that expected = observed, or
      equivalently so that the likelihood of the training data is
      maximized.  (If you are willing to somewhat relax the
      constraints to "expected &approx; observed" in exchange for
      making the entropy even higher, you can define a relaxed version
      of the entropy maximization problem.  In this case, the solution
      is a log-linear model that maximizes the
      &ell;<sub>2</sub>-regularized or &ell;<sub>1</sub>-regularized
      log-likelihood, depending on how you relax the
      constraints.)</small></blockquote>

  <p><b>Other names for unconditional log-linear models.</b>  Suppose
    the conditioning context in p(outcome | context) happens to be
    empty, so that we are just modeling p(outcome) as in the early
    lessons of this tutorial. Then instead of a conditional random
    field, we have the slightly simpler <u>Markov random field
      (MRF)</u>, also known as an <u>undirected graphical
      model</u>, <u>exponential model</u>, or <u>Gibbs distribution</u>.</p>

  <blockquote><font size=-1>Many other common probability
      distributions can be expressed as exponential models (they are
      said to be in the <u>exponential family</u>).  For example, a
      Gaussian (normal) distribution over a pair of real
      variables <i>y</i> =
      (<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>) <!-- &isin;
      &real;<sup>2</sup> --> has the form p(<i>y</i>) = (1/Z)
      exp(quadratic function of <i>y</i>).  So it is merely a
      log-linear model with feature vector <i>f(<i>y</i>)</i> =
      (<i>y</i><sub>1</sub>,
      <i>y</i><sub>2</sub>, <i>y</i><sub>1</sub><sup>2</sup>, <i>y</i><sub>2</sub><sup>2</sup>,
      <i>y</i><sub>1</sub><i>y</i><sub>2</sub>).  The feature weights
      correspond to the coefficients of the quadratic function: they
      determine the mean, variances, and covariance.</font></blockquote>

  <p><b>Other kinds of probabilistic models.</b> The log-linear
    formula is not a sacred relic.  You could model p(<i>y</i> | <i>x</i>)
    with any formula that defines a valid probability distribution, and
    estimate its parameters from data, perhaps by maximizing
    likelihood.</p>

  <p>In general, your model should still consider features of
    (<i>x</i>,<i>y</i>) that might plausibly affect the probability.
    It's just that you can combine them quite differently.  For example,
    check out <u>decision trees</u> and <u>decision forests</u>,
    or <u>neural networks</u>.</p>

  <p><b>Linear decision rules.</b> Often in machine learning, you just
    want to build a <u>classifier</u> to pick the <i>best</i>
    prediction <i>y</i> in a given context <i>x</i>.  You get to train
    your prediction method on some (<i>x</i>,<i>y</i>) pairs.</p>

  <p>One approach is to always predict the <i>y</i> that maximizes
    p(<i>y</i> | <i>x</i>).  But this is the same as the <i>y</i> that
    maximizes the linear score &theta;
    &sdot; <i>f</i>(<i>x</i>,<i>y</i>), if you're using a log-linear
    model p(<i>y</i> | <i>x</i>) = (1/<i>Z</i>) exp(&theta;
    &sdot; <i>f</i>(<i>x</i>,<i>y</i>)).</p>

  <p>In <u>regression</u>, you try to choose a &theta; such that
    &theta; &sdot; <i>f</i>(<i>x</i>) generally does a good job of
    predicting <i>y</i> from <i>x</i>, where <i>y</i> is a real
    number.  Our log-linear models are doing <u>classification</u>: 
    we want to choose a &theta; such that maximizing &theta;
    &sdot; <i>f</i>(<i>x</i>,<i>y</i>) generally does a good job of
    predicting <i>y</i> from <i>x</i>, where <i>y</i> can be any kind
    of object.</p>

  <p>So why, unlike regression, does classification need to convert
    &theta; &sdot; <i>f</i>(<i>x</i>,<i>y</i>) to a probability (by
    exponentiating and renormalizing)?  We do it only for the purposes
    of training&mdash;it's because the conditional log-likelihood
    training objective refers to p(<i>y</i> | <i>x</i>).  The point of
    the training objective is to evaluate whether &theta; does a good
    job.<p>

  <p>But there are other plausible training objectives that look at
    the linear score &theta; &sdot; <i>f</i>(<i>x</i>,<i>y</i>)
    without converting it to a probability.  Most straightforwardly,
    you might try to choose &theta; to maximize the <i>accuracy</i> of
    the classifier on training data.  Alas, that objective is
    generally NP-hard to optimize, and it might overfit.
    But <u>support vector machines</u> (SVMs) optimize a related
    objective that doesn't have those problems and has theoretical
    guarantees.  The <u>averaged perceptron</u> and <u>boosting</u>
    are also in this family.</p>

  <p><b>Nonlinear decision rules.</b> Why confine yourself to linear
    scoring functions?  While <u>neural networks</u> and other
    arbitrary nonlinear functions can be hard to optimize, a great
    general technique is to write the score as &theta; &sdot;
    &Phi;(<i>f</i>(<i>x</i>,<i>y</i>)), where &Phi; is some nonlinear
    transform of your original feature vector.  Because you still have
    a linear scoring function on the transformed feature vector, you
    can still learn and classify as efficiently as before, except that
    the transformed feature vector might be longer.</p>

  <p>Sometimes even that inefficiency can be eliminated.  With the
    <u>kernel trick</u>, training-time parameter updates and test-time
    classification both work with an implicit representation of
    &theta;, without ever explicitly computing the high-dimensional
    vectors &theta; and &Phi;(...).  In particular, if &Phi; is chosen
    carefully, then nearly all the methods discussed here can be kept
    efficient, <i>provided that the set of possible outcomes <i>y</i>
    for each <i>x</i> is small</i>, as in logistic regression.
</p>
</div>
